---
title: "flat_minimal.Rmd empty"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r development, include=FALSE}
library(testthat)

# Sample size calculation  Zhou et al
sample_size_calculation <- function(sensitivity, alpha, power, margin, prevalence = NULL, prevalence_power = NULL){
  alpha_val         <- 1-alpha/2
  
  sample_size <- ((qnorm(alpha_val) + qnorm(power)) * sqrt(sensitivity*(1-sensitivity)))^2 / margin^2
  
  if(!is.null(prevalence)){
    a           <- prevalence^2
    c           <- sample_size^2
    b           <- -(2 * sample_size * prevalence + qnorm(prevalence_power)^2 * prevalence * (1 - prevalence))
    delta       <- b^2 - 4 * a * c
    sample_size <- (-b + sqrt(delta)) / (2*a)
  }
}



n_tot_calculation <-function(prevalence, sample_size, prevalence_power){
     a           <- prevalence^2
    c           <- sample_size^2
    b           <- -(2 * sample_size * prevalence + qnorm(prevalence_power)^2 * prevalence * (1 - prevalence))
    delta       <- b^2 - 4 * a * c
    sample_size <- (-b + sqrt(delta)) / (2*a)
    return(sample_size)
}

 power_calc <- function(sample_size, margin, sensitivity, alpha) {
   alpha_val         <- 1-alpha/2
   (sqrt(sample_size * margin^2) / (sqrt(sensitivity*(1-sensitivity)))) - qnorm(alpha_val) -> qp
   power <- pnorm(qp)
   return(power)
 }
 
 
 margin_calc <- function(alpha, power, sensitivity, sample_size) {
   alpha_val         <- 1-alpha/2
   margin <- sqrt((((qnorm(alpha_val) + qnorm(power)) * sqrt(sensitivity*(1-sensitivity)))^2)/sample_size)
   return(margin)
 }
 
 
 sample_size_calculation(sensitivity= 0.8, alpha=0.05, power=0.8, margin=0.1, prevalence = NULL, prevalence_power = NULL)
sample_size_calculation(sensitivity= 0.97, alpha=0.05, power=0.8, margin=0.05, prevalence = NULL, prevalence_power = NULL)
n_tot_calculation(prevalence = 0.05, sample_size=60, prevalence_power=0.8)

n_tot_calculation(prevalence = 0.1, sample_size=60, prevalence_power=0.8)
n_tot_calculation(prevalence = 0.2, sample_size=60, prevalence_power=0.8)

power_calc(sample_size = 60, margin=0.15, sensitivity=0.8, alpha=0.05)
power_calc(sample_size = 200, margin=0., sensitivity=0.97, alpha=0.05)

margin_calc(0.05, 0.8, 0.8, 60)


```

<!--
 You need to run the 'description' chunk in the '0-dev_history.Rmd' file before continuing your code there.
-->

### Sample size calculation  
Calculates the  sample size to estimate the accuracy of a single diagnostic test, and generates a power table based on Zhou et al.
Calculates sample size in terms of true positives/ true negatives based on the parameters entered.
When prevalence and prevalence power are not entered the function gives the number of true positives/negatives. When they are entered, it gives the total number of subjects to be screened.

```{r function-sample_size_calculation}
#' sample_size_calculation
#'
#' @param sen_spe numeric, expected sensitivity/specificity
#' @param alpha numeric, significance level
#' @param power numeric, desired power
#' @param margin numeric, the error margin - half width of the confidence interval
#' @param prevalence numeric, prevalence of the disease. 
#' @param prevalence_power numeric, the power to detect the prevalence
#' @param performance_characteristic character, "sen" for sensitivity, "spe" for specificity
#'
#' @return sample size 
#' 
#' @references Zhou XH, Obuchowski NA and McClish DK. Statistical Methods in Diagnostic Medicine. 2011;2:193-228
#' @export
#'
#' @examples
sample_size_calculation <- function(sen_spe, alpha, power, margin, prevalence = NULL, prevalence_power = NULL, performance_characteristic = "sen") {
  alpha_val         <- 1-alpha/2
  
  sample_size <- ((qnorm(alpha_val) + qnorm(power)) * sqrt(sen_spe*(1-sen_spe)))^2 / margin^2


  
  if(!is.null(prevalence)){
      if(performance_characteristic == "spe"){
    prevalence <- 1-prevalence
  }
    a           <- prevalence^2
    c           <- sample_size^2
    b           <- -(2 * sample_size * prevalence + qnorm(prevalence_power)^2 * prevalence * (1 - prevalence))
    delta       <- b^2 - 4 * a * c
    sample_size <- (-b + sqrt(delta)) / (2*a)
  }
  return(ceiling(sample_size))
}

```


```{r examples-sample_size_calculation}
 sample_size_calculation(sen_spe= 0.8, alpha=0.05, power=0.8, margin=0.05, prevalence = NULL, prevalence_power = NULL, performance_characteristic = "sen") 
# Number of true positives for a sensitivity of 80%

 sample_size_calculation(sen_spe= 0.8, alpha=0.05, power=0.8, margin=0.05, prevalence = 0.1, prevalence_power = 0.9, performance_characteristic = "sen") 
 # Total  number of patients to be screened to test 80% sensitivity with 10% prevalence and 80% prevalence power


```

```{r tests-sample_size_calculation}
test_that("sample_size_calculation works", {
  expect_equal(sample_size_calculation(sen_spe= 0.8, alpha=0.05, power=0.8, margin=0.05, prevalence = NULL, prevalence_power = NULL, performance_characteristic = "sen"), 503)
})
```

### Total N Calculation: 
 Calculates the total number of subjects to be screened to estimate the accuracy of a single diagnostic test, based on a known number of confirmed positives/negatives that is needed, an estimate of prevalence, and prevalence power.

```{r function-n_tot_calculation}
#' Total N Calculation
#' 
#' 
#' @param prevalence Disease prevalence
#' @param sample_size Number of confirmed cases by reference
#' @param prevalence_power the power to detect the prevalence
#' 
#' #'
#' @return total number of subjects to be screened 
#' @export
#' 
#' @references Zhou XH, Obuchowski NA and McClish DK. Statistical Methods in Diagnostic Medicine. 2011;2:193-228
#'
#' @examples
n_tot_calculation <-function(prevalence, sample_size, prevalence_power){
     a           <- prevalence^2
    c           <- sample_size^2
    b           <- -(2 * sample_size * prevalence + qnorm(prevalence_power)^2 * prevalence * (1 - prevalence))
    delta       <- b^2 - 4 * a * c
    N <- (-b + sqrt(delta)) / (2*a)
    return(ceiling(N))
}
```

```{r examples-n_tot_calculation}

 n_tot_calculation(sample_size=503, prevalence = 0.1, prevalence_power = 0.9) 
# Total  number of patients to be screened to test 80% sensitivity with 10% prevalence and 80% prevalence power. 
# Should give the same number as the second example of sample_size_calculation

```

```{r tests-n_tot_calculation}
test_that("n_tot_calculation works", {
  expect_equal(n_tot_calculation(sample_size=503, prevalence = 0.1, prevalence_power = 0.9 ), 5311)
})
```


### Error margin Calculation  

Calculates the margin of error for one side based on the significance, power, sensitivity/specificity, and the number true positives/negatives, to estimate the accuracy of a single diagnostic test.



```{r function-margin_calc}

#' Error Margin Calculation
#'
#' @param alpha numeric, significance level
#' @param power numeric, desired power
#' @param sen_spe numeric, sensitivity/specificity of a test
#' @param sample_size numeric, number of confirmed cases i.e. positives/negatives by reference
#'
#' @return error margin on one side of the confidence interval
#' @references Zhou XH, Obuchowski NA and McClish DK. Statistical Methods in Diagnostic Medicine. 2011;2:193-228
#' 
#' @export
#'
#' @examples
 margin_calc <- function(alpha, power, sen_spe, sample_size) {
   alpha_val         <- 1-alpha/2
   margin <- sqrt((((qnorm(alpha_val) + qnorm(power)) * sqrt(sen_spe*(1-sen_spe)))^2)/sample_size)
   return(round(margin, digits=3))
 }
 
```


```{r examples-margin_calc}

 margin_calc(alpha=0.05, power=0.8, sen_spe=0.8, sample_size=502) 
# Error margin on one side. Using the same parameters as sample_size_calculation. Should be ~0.05

```

```{r tests-margin_calc}
test_that("margin_calc works", {
  expect_equal(margin_calc(alpha=0.05, power=0.8, sen_spe=0.8, sample_size=502), 0.05)
})
```


### Calculate Power  

Calculate the power of the design based on sample size, error margin, sensitivity/specificity and significance level, for the estimation of the accuracy of a single diagnostic test.

```{r function-power_calc}
#' Power Calculation
#'
#' @param sample_size numeric, confirmed positives/negatives by reference standard
#' @param margin numeric, the error margin
#' @param sen_spe test performance characteristice estimate
#' @param alpha significance level
#'
#' @return Power
#' @export
#' @references Zhou XH, Obuchowski NA and McClish DK. Statistical Methods in Diagnostic Medicine. 2011;2:193-228
#' 
#' @examples
 power_calc <- function(sample_size, margin, sen_spe, alpha) {
   alpha_val         <- 1-alpha/2
   (sqrt(sample_size * margin^2) / (sqrt(sen_spe*(1-sen_spe)))) - qnorm(alpha_val) -> qp
   power <- pnorm(qp)
   return(round(power, digits = 3))
 }
 
```


```{r examples-power_calc}

 power_calc(alpha=0.05, margin=0.05, sen_spe=0.8, sample_size=502) 
# Power of the study. Using the same parameters as sample_size_calculation. Should be ~80%

```

```{r tests-power_calc}
test_that("power_calc works", {
  expect_equal(power_calc(alpha=0.05, margin=0.05, sen_spe=0.8, sample_size=502), 0.8)
})
```



## gen_pow_curve

Generates a table with sample size (confirmed cases and to be screened) calculated for a sequence of desired powers using the "sample_size_calculation" function.
    
```{r function-gen_pow_curve}
#' Generate power curve
#' 
#' Calls sample_size_calculation twice to calculate the number of confirmed cases and number of participants to be screened for a sequence of desired powers.
#' 
#' @param seq A sequence of statistical powers for which sample size is to be calculated
#' @param sen_spe expected sensitivity/specificity
#' @param alpha significance level
#' @param margin error margin (half width of the confidence interval)
#' @param prevalence expected disease prevalence
#' @param prevalence_power power to predict the prevalence
#' @param performance_characteristic the performance characteristic that is being evaluated
#'
#' @return A data frame with values ready to plot a power curve
#' 
#' @export
gen_pow_curve <- function(seq, sen_spe, alpha, margin,
                          prevalence, prevalence_power, performance_characteristic = "sen"){

  dt <- data.frame()
  for (pow in seq) {
    #browser()
    n <- sample_size_calculation(sen_spe = sen_spe,
                                 alpha = alpha,
                                 power = pow,
                                 margin = margin,
                                 prevalence = NULL,
                                 prevalence_power = NULL ,
                                 performance_characteristic = performance_characteristic)
    N <- sample_size_calculation(sen_spe = sen_spe,
                                 alpha = alpha,
                                 power = pow,
                                 margin = margin,
                                 prevalence = prevalence,
                                 prevalence_power = prevalence_power ,
                                 performance_characteristic = performance_characteristic)
    table <- data.frame(`Power (%)` = pow*100 ,`n confirmed cases` = n, `n to screen` = N, check.names = FALSE )
    dt <- rbind(dt, table)
  }
  return(dt)
}
```
  
```{r example-gen_pow_curve}
pow_list <- c(0.8, 0.85, 0.9, 0.95)
    dt <- gen_pow_curve(seq = pow_list,
                        sen_spe = 0.9,
                        alpha = 0.05,
                        margin = 0.05,
                        prevalence = 0.4,
                        prevalence_power = 0.8 ,
                        performance_characteristic = "sen")
```
  
```{r tests-gen_pow_curve}
pow_list <- c(0.8, 0.85, 0.9, "a")

test_that("gen_pow_curve works", {
  expect_error(gen_pow_curve(seq = pow_list,
                        sen_spe = 0.9,
                        alpha = 0.05,
                        margin = 0.05,
                        prevalence = 0.4,
                        prevalence_power = 0.8 ,
                        performance_characteristic = "sen")) 
})
```
  



### Sample Size for proportion estimation

Calculate the sample size necessary to estimate a proportion in a finite or infinite proportion. (Daniel et. al)


```{r function-sample_size_pop_prop}

#' Sample Size Population Proportion
#'
#' @param alpha numeric, significance level
#' @param p   numeric, estimated proportion
#' @param margin numeric, error margin
#' @param N numeric, population size
#'
#' @return sample size for the estimation of the proportion
#' @export
#'
#' @references Daniel  WW  (1999).  Biostatistics:  A  Foundation for   Analysis   in   the   Health   Sciences.   7th edition. New York: John Wiley & Sons.
#'
#' @examples
n_pop_prop <- function(alpha, p, margin, N=NULL) {
  alpha_val         <- 1-alpha/2
  X <- qnorm(alpha_val)^2 * p * (1-p) / margin^2
  if (is.null(N)){
      n = X
  } else {
      n = N*X / (X + N-1)
  }
  return(ceiling(n))
}

```

```{r examples-sample_size_pop_prop}

 n_pop_prop(alpha = 0.05, p =  0.5, margin = 0.1, N = 1000) 

# sample size for a population of 1000 people to estimate that at least half of the population has the desired characteristic with an error margin of 10%

 n_pop_prop(alpha = 0.05, p =  0.5, margin = 0.1) 
 # same calculation in an infinite population
```

```{r tests-n-n_por_prop}
test_that("n_por_prop works", {
   expect_equal(n_pop_prop(alpha = 0.05, p =  0.5, margin = 0.1), 97)
    expect_equal(n_pop_prop(alpha = 0.05, p =  0.5, margin = 0.1, N=100), 50)
})
```


### Sample Size for cluster randomized trials

Calculates the number of clusters necessary for a cluster randomized trials, based on an estimated change in the proportions between the control and intervention groups.
    
```{r function-cluster_random_sample_size}
#' Cluster Random Sample Size
#' 
#' Gives the number of clusters (pairs of clusters for paired designs) required for cluster randomized trials
#' 
#' @param alpha significance level
#' @param power the desired power
#' @param coef_var between-cluster variation, use 0.25 if unknown as this is the estimated maximum
#' @param A Adjustment for loss of degrees of freedom (1 for unpaired trials, 2 in paired trials)
#' @param pi proportion in the intervention group
#' @param pc proportion in the control group
#' @param CS an estimate of the cluster size
#'
#' @return number of clusters required in each treatment group in an unmatched design, and total pairs in a paired design.
#' @references Hayes, R. J., & Moulton, L. H. (2017). Cluster randomised trials. Chapman and Hall/CRC.
#' 
#' @export
cluster_random_sample_size <- function(alpha, power, coef_var=0.25, A=2, pi, pc, CS){
  alpha_val <- 1-alpha/2
  qq <- ( qnorm(alpha_val) +qnorm(power))^2
  i <- pi*(1-pi)/CS
  c <- pc*(1-pc)/CS
  s <- (coef_var^2)*(pi^2 + pc^2)
  f <-(i+c+s)/((pi-pc)^2)
  N <- A + qq*f
  return(ceiling(N))

}
```
  
```{r example-cluster_random_sample_size}

# The matched trial protocol required 80% power of detecting a 50% reduction of annual HIV incidence from an assumed 1% in the control arm (π0 = 0.02 over 2 years) to 0.5% in the intervention arm (π1 = 0.01). Thus, with m = 1000 adults followed up in each cluster, the number of clusters required per treatment arm in a matched design was gives 6.8 = 7 cluster pairs
cluster_random_sample_size(alpha=0.05, power=0.8, coef_var=0.25, A =2, pi=0.01, pc=0.02, CS=1000)
```
  
```{r tests-cluster_random_sample_size}
# Unpaired design - the number of clusters required for each treatment group
# incidence of a disease in control group: 0.0148
# incidence in intervention group: 0.0104
# desired power: 0.8
# significance : 0.05
# people per cluster : 424
# variation in clusters: 0.29
test_that("cluster_random_sample_size works", {
  expect_equal(cluster_random_sample_size(alpha = 0.05, power =0.8, coef_var = 0.29, A =1, pi =0.0104, pc = 0.0148, CS = 424), 36)
})
```
  


### Effective Sample Size

The effective sample size (ESS) accounts for the clustering structure in clustered data and provides an estimate of the sample size needed to achieve the same level of precision as a simple random sample of the same size.

E.g., if you have 4 physicians’ offices enrolling 32 patients each, you have 128 subjects in your study. Depending on the intracluster correlation coefficient and the design effect, however, you may effectively have far fewer subjects enrolled in your trial from a statistical perspective i.e., the effective sample size.

```{r function-effective_sample_size}
#' Effective Sample Size
#' 
#' Gives the 'real' sample size in a clustered trial, accounting for the net loss of data due to the similarities among participants in the same cluster. 
#' @param m number of participants in a cluster
#' @param k number of clusters
#' @param ICC intracluster correlation coefficient
#' 
#' @return effective sample size (actual sample size (mk) divided by the design effect (1 + ICC * (m - 1)))
#' 
#' @references Killip S, Mahfoud Z, Pearce K. (2004). What is an intracluster correlation coefficient? Crucial concepts for primary care researchers. Ann Fam Med. 
#' 
#' @export
effective_sample_size <- function(m, k, ICC){
  ss = m*k
  de = (1 + ICC * (m - 1))
  N = ss/de
  return(ceiling(N))
}

```

```{r example-effective_sample_size}

# In a cluster randomized controlled trial, you have 8 clusters with 30 participants per cluster i.e., total sample size of 240 and an ICC of 0.2. A simple method to calculate the power associated with this sample size is to first calculate the effective sample size i.e., the sample size in a simple random sample that would give the same level of precision, and then do a power calculation using the ESS. 

effective_sample_size(m = 30, k =8, ICC = 0.2)

```

```{r tests-effective_sample_size}
# Calculates effective sample size
# number of participants in a cluster: 32
# number of clusters: 4
# intracluster correlation coefficient: 0.017

test_that("effective_sample_size works", {
  expect_equal(effective_sample_size(m = 32, k = 4, ICC = 0.017), 84)
})

```

## Compare proportions in a 2 sample cross-over design
    
```{r function-compare_proportions_cross}
#' compare_proportions_cross
#' 
#' Sample size calculation to compare proportions in a cross-over design
#' 
#' @param alpha significance level, default 5%
#' @param power desired power, default 80%
#' @param p_diff difference between the proportions of incidence
#' @param var variance of the d
#' @references Chow, S. C., Shao, J., Wang, H., & Lokhnygina, Y. (2017). Sample size calculations in clinical research. chapman and hall/CRC.

#' @return Sample size
#' 
#' @export
compare_proportions_cross <- function(alpha = 0.05, power = 0.8, p_diff, var = 0.5){
  alpha_val         <- 1-alpha/2
  zz <- (qnorm(alpha_val) + qnorm(power))^2
  ss <- var^2
  denom <- (p_diff^2)*2
  sample_size <- (zz*ss)/denom
  return(ceiling(sample_size))
  
     
}
```
  
```{r example-compare_proportions_cross}
# Difference between the two proportions are predicted to be 10%
compare_proportions_cross(alpha = 0.05, power = 0.8, p_diff = 0.1, var = 0.5)
```
  
```{r tests-compare_proportions_cross}
test_that("compare_proportions works", {
  expect_equal(compare_proportions_cross(alpha = 0.05, power =0.8, p_diff = 0.2, var = 0.5), 25)
})
```
  
# sample_size_non_inferiority
    
```{r function-sample_size_non_inferiority}
#' Sample Size non-inferiority
#' 
#' Gives the sample size for a diagnostic accuracy non-inferiority trial, based on estimated accuracy for each test and a minimum non-acceptable difference (Eq. 6.24 from Zhou et al. 2011)  Variance is calculated using the Eq.6.21 from Zhou et al., which was originally published in Blume et al. 2009.
#' 
#' @param se1 Sensitivity/Specificity of the comparator test
#' @param se2 Sensitivity/Specificity of the index test
#' @param r Correlation coefficient: 0 for an unpaired design, 0.5 for a paired design. Default = 0.5
#' @param min_dif Minimum non-acceptable difference
#' @param alpha Significance level
#' @param power Desired power
#'
#' @return Sample size
#' 
#' @export
#' 
#' @references Zhou XH, Obuchowski NA and McClish DK. Statistical Methods in Diagnostic Medicine. 2011;2:193-228
#' @references Blume J. D. (2009). Bounding Sample Size Projections for the Area Under a ROC Curve. Journal of statistical planning and inference, 139(1), 711–721.
#' 


sample_size_non_inferiority <- function(se1, se2, r, min_dif, alpha, power ){
  
  var <- se1*(1-se1) + se2*(1-se2) - 2*r*sqrt(se1*(1-se1)*se2*(1-se2))

  nominator <- (qnorm(alpha) + qnorm(1-power))^2 * var
  denominator <- (se1-se2-min_dif)^2
  sample_size <- nominator/denominator
  sample_size <- ceiling(sample_size)
  
  return(sample_size)
    
}
```

```{r example-sample_size_non_inferiority}
sample_size_non_inferiority(se1 = 0.9, se2 = 0.88, r = 0.5, min_dif=0.05, alpha=0.05, power=0.8)
```
  
```{r tests-sample_size_non_inferiority}
test_that("sample_size_non_inferiority works", {
  expect_true(inherits(sample_size_non_inferiority, "function")) 
})
```
  
  
  
# ss_compare_sen_spe
    
```{r function-ss_compare_sen_spe}
#' Sample Size for detecting a difference between two tests 
#' 
#' Sample size calculation when comparing sensitivities/specifies in paired groups by McNemar, according to Beam, 1992, Table 4. Three sample sizes are given taking into account the minimum (N_min) and the maximum (N_max) bounds on the probability of disagreement, and their mean (N_mean). The original formula is for equivalence testing. The hypothesis of detecting a specified difference (delta_m) was done as in Blackwleder 1982 by introducing the specified difference to the denominator.
#' 
#' 
#' @param theta_s numeric value between 0 and 1. performance estimate of standard test
#' @param theta_e numeric value between 0 and 1. performance estimate of experimental test
#' @param delta_m numeric value. maximal acceptable difference to conclude non-inferiority.
#' @param alpha numeric value. Significance level
#' @param beta numeric value. beta = 1 - Power 

#' 
#' @importFrom stats qnorm
#'
#' @return numeric values giving the min-mean-max number of samples required
#' @references Blackwelder WC. "Proving the Null Hypothesis" in Clinical Trials. Control. Clin. Trials 1982; 3:345-353.
#' @references Beam, C. A. (1992). Strategies for improving power in diagnostic radiology research. American Journal of Roentgenology 159, 631-637.
#' @export
#' 
  ss_compare_sen_spe  <- function(theta_s, theta_e, delta_m, alpha = 0.05, beta = 0.8){
    phi_min <- theta_s - theta_e
  phi_max <- theta_s * (1 - theta_e) + theta_e * (1 - theta_s)
  phi_vec <- c(phi_min, phi_max)


  ss.range <- sapply(phi_vec, function(phi){
    (qnorm(1 - alpha) * sqrt(phi) + qnorm(beta) * sqrt(phi-phi_min^2))^2 / (phi_min-delta_m)^2
  })
  
  Ns <- ceiling(c(N_min = ss.range[1], N_mean = mean(ss.range[1:2]), N_max = ss.range[2]))

  return(Ns)


}
```
  
```{r example-ss_compare_sen_spe}
#' \dontrun{
ss_compare_sen_spe(theta_s = 0.45, theta_e = 0.43, delta_m = 0.07, beta = 0.8)
ss_compare_sen_spe(theta_s = 0.45, theta_e = 0.43, delta_m = 0, beta = 0.8)
#' }
```
  
```{r tests-ss_compare_sen_spe}
test_that("ss_compare_sen_spe works", {
  expect_true(inherits(ss_compare_sen_spe, "function")) 
})
```
  
  


```{r development-inflate, eval=FALSE}
# Run but keep eval=FALSE to avoid infinite loop
# Execute in the console directly
fusen::inflate(flat_file = "dev/flat_minimal.Rmd", vignette_name = "Sample Size Calculations", overwrite = TRUE)
```
